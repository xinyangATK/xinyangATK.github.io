---
---

@article{wang2023align,
      title={Tuning Multi-mode Token-level Prompt Alignment across Modalities}, 
      author={Wang, Dongsheng and Li, Miaoge and Liu, Xinyang, and  Xu Mingsheng and Chen, Bo and Zhang Hanwang},
      journal={37th Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)},
      year={2023},
      preview={ALIGN.png},
      abstract={Prompt tuning pre-trained vision-language models have demonstrated significant potential in improving  open-world visual concept understanding. However, prior works only primarily focus on single-mode (only one prompt for each modality) and holistic level (image or sentence) semantic alignment, which fails to capture the sample diversity, leading to sub-optimal prompt discovery. To address the limitation, we propose a multi-mode token-level tuning framework that leverages the optimal transportation to learn and align a set of prompt tokens across modalities. Specifically, we rely on two essential factors: 1) multi-mode prompts discovery, which guarantees diverse semantic representations, and 2) token-level alignment, which helps explore fine-grained similarity. Thus, the similarity can be calculated as a hierarchical transportation problem between the modality-specific sets. Extensive experiments on popular image recognition benchmarks show the superior generalization and few-shot abilities of our approach. The qualitative analysis demonstrates that the learned prompt tokens have the ability to capture diverse visual concepts.},
}

@article{li2023patchct,
      title={PatchCT: Aligning Patch Set and Label Set with Conditional Transport for Multi-Label Image Classification}, 
      author={Li*, Miaoge and Wang*, Dongsheng and Liu, Xinyang, and  Zeng, Zequn and Lu, Ruiying and Chen, Bo and Zhou, Mingyuan},
      journal={The IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)},
      year={2023},
      preview={PatchCT.png},
      abstract={Multi-label image classification is a prediction task that aims to identify more than one label from a given image. This paper considers the semantic consistency of the latent space between the visual patch and linguistic label domains and introduces the conditional transport (CT) theory to bridge the acknowledged gap. While recent cross-modal attention-based studies have attempted to align such two representations and achieved impressive performance, they required carefully-designed alignment modules and extra complex operations in the attention computation. We find that by formulating the multi-label classification as a CT problem, we can exploit the interactions between the image and label efficiently by minimizing the bidirectional CT cost. Specifically, after feeding the images and textual labels into the modality-specific encoders, we view each image as a mixture of patch embeddings and a mixture of label embeddings, which capture the local region features and the class prototypes, respectively. CT is then employed to learn and align those two semantic sets by defining the forward and backward navigators. Importantly, the defined navigators in CT distance model the similarities between patches and labels, which provides an interpretable tool to visualize the learned prototypes. Extensive experiments on three public image benchmarks show that the proposed model consistently outperforms the previous methods.},
      arxiv={2307.09066},
      code={https://github.com/keepgoingjkg/PatchCT},
}

@article{liu2023patch,
  title={Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models},
  author={Liu*, Xinyang and Wang*, Dongsheng and Li, Miaoge and Duan, Zhibin and Xu, Yishi and Chen, Bo and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2303.09100},
  year={2023},
  preview={PBPrompt.png},
  abstract={For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwardly extended to the conditional case where the instance-conditional prompts are generated to improve the generalizability. Extensive experiments on 15 datasets show promising transferability and generalization performance of our proposed model.},
  arxiv={2303.09100},
  selected={true},
}

@article{mlr-v202-duan23c,
  title={Bayesian Progressive Deep Topic Model with Knowledge Informed Textual Data Coarsening Process},
  author={Duan*, Zhibin and Liu*, Xinyang and Su, Yudi and Xu, Yishi and Chen, Bo and Zhou, Mingyuan},
  journal={In the 40th International Conference on Machine Learning (<strong>ICML</strong>)},
  year={2023},
  preview={ProGBN.png},
  abstract={Deep topic models have shown an impressive ability to extract multi-layer document latent representations and discover hierarchical semantically meaningful topics. However, most deep topic models are limited to the single-step generative process, despite the fact that the progressive generative process has achieved impressive performance in modeling image data. To this end, in this paper, we propose a novel progressive deep topic model that consists of a knowledge-informed textural data coarsening process and a corresponding progressive generative model. The former is used to build multi-level observations ranging from concrete to abstract, while the latter is used to generate more concrete observations gradually. Additionally, we incorporate a graph-enhanced decoder to capture the semantic relationships among words at different levels of observation. Furthermore, we perform a theoretical analysis of the proposed model based on the principle of information theory and show how it can alleviate the wellknown “latent variable collapse” problem. Finally, extensive experiments demonstrate that our proposed model effectively improves the ability of deep topic models, resulting in higher-quality latent document representations and topics.},
  pdf={https://proceedings.mlr.press/v202/duan23c.html},
  code={https://github.com/xinyangATK/ProGBN},
  selected={true},
}





