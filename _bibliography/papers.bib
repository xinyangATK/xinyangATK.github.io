---
---

@article{liu2023patch,
  title={Patch-Token Aligned Bayesian Prompt Learning for Vision-Language Models},
  author={Liu*, Xinyang and Wang*, Dongsheng and Li, Miaoge and Duan, Zhibin and Xu, Yishi and Chen, Bo and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2303.09100},
  year={2023},
  preview={PBPrompt.png},
  abstract={For downstream applications of vision-language pre-trained models, there has been significant interest in constructing effective prompts. Existing works on prompt engineering, which either require laborious manual designs or optimize the prompt tuning as a point estimation problem, may fail to describe diverse characteristics of categories and limit their applications. We introduce a Bayesian probabilistic resolution to prompt learning, where the label-specific stochastic prompts are generated hierarchically by first sampling a latent vector from an underlying distribution and then employing a lightweight generative model. Importantly, we semantically regularize prompt learning with the visual knowledge and view images and the corresponding prompts as patch and token sets under optimal transport, which pushes the prompt tokens to faithfully capture the label-specific visual concepts, instead of overfitting the training categories. Moreover, the proposed model can also be straightforwardly extended to the conditional case where the instance-conditional prompts are generated to improve the generalizability. Extensive experiments on 15 datasets show promising transferability and generalization performance of our proposed model.},
  arxiv={2303.09100},
  selected={true},
}

@article{liu2023patch,
  title={Bayesian Progressive Deep Topic Model with Knowledge Informed Textual Data Coarsening Process},
  author={Duan*, Zhibin and Liu*, Xinyang and Su, Yudi and Xu, Yishi and Chen, Bo and Zhou, Mingyuan},
  journal={In the 40th International Conference on Machine Learning},
  year={2023},
  preview={ProGBN.png},
  abstract={Deep topic models have shown an impressive abil- ity to extract multi-layer document latent repre- sentations and discover hierarchical semantically meaningful topics. However, most deep topic models are limited to the single-step generative process, despite the fact that the progressive gen- erative process has achieved impressive perfor- mance in modeling image data. To this end, in this paper, we propose a novel progressive deep topic model that consists of a knowledge-informed tex- tural data coarsening process and a correspond- ing progressive generative model. The former is used to build multi-level observations ranging from concrete to abstract, while the latter is used to generate more concrete observations gradually. Additionally, we incorporate a graph-enhanced de- coder to capture the semantic relationships among words at different levels of observation. Further- more, we perform a theoretical analysis of the proposed model based on the principle of informa- tion theory and show how it can alleviate the well- known “latent variable collapse” problem. Finally, extensive experiments demonstrate that our pro- posed model effectively improves the ability of deep topic models, resulting in higher-quality la- tent document representations and topics.},
  selected={true},
}
